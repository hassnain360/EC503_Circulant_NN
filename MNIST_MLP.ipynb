{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9b89453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#\n",
    "#   Multilayer Perceptron for MNIST \n",
    "#\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19035e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ebd408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variables\n",
    "weights = []\n",
    "bias = []\n",
    "layers_config = [784, 512, 10]\n",
    "average_weights = []\n",
    "average_bias = []\n",
    "eta = 0.01\n",
    "epoch_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0038f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def ReLU_derivative(values):\n",
    "    result = [1 if x > 0 else 0 for x in values]\n",
    "    return result\n",
    "\n",
    "def tanh_activation(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - (np.tanh(x) ** 2)\n",
    "\n",
    "def Softmax(x):\n",
    "    return np.exp(x - np.max(x))/(np.sum(np.exp(x - np.max(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e4b1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(input_image):\n",
    "    a = []\n",
    "    a.append(input_image.reshape(len(input_image[0])*len(input_image[1]),1))\n",
    "    \n",
    "    for i in range(1, len(layers_config)-1):\n",
    "        a.append(ReLU((weights[i] @ a[i-1]).reshape(len(weights[i]), 1) + bias[i]))\n",
    "    y_hat = Softmax((weights[-1] @ a[-1]) + bias[-1]).reshape(len(weights[-1]),)\n",
    "    a.append(y_hat)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fec81b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(a, ground_output_y):\n",
    "    delta_error = list(np.empty_like(a))\n",
    "    index_count = len(layers_config) - 1\n",
    "    delta_error[index_count] = (a[index_count] - ground_output_y).reshape(len(a[index_count]), 1)\n",
    "    average_bias[index_count] = average_bias[index_count] + delta_error[index_count] # Output Layer\n",
    "    average_weights[index_count] = average_weights[index_count] + (delta_error[index_count] @ a[index_count - 1].T) # Output Layer\n",
    "    for i in range(index_count - 1, 0, -1):\n",
    "        h_derivative = np.array(ReLU_derivative(a[i])).reshape(1, len(a[i])) * np.eye(len(a[i]))\n",
    "        delta_error[i] = h_derivative.T @ weights[i+1].T @ delta_error[i+1]\n",
    "        average_bias[i] = average_bias[i] + delta_error[i]\n",
    "        average_weights[i] = average_weights[i] + (delta_error[i] @ a[i-1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21199ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# He Normalization\n",
    "def initialize_weights():\n",
    "    if len(layers_config) < 3:\n",
    "        print(\"Incorrect network structure. Check the neural network layer configuration\")\n",
    "    else:\n",
    "        layer_count = len(layers_config)\n",
    "        weights.append([])\n",
    "        bias.append([])\n",
    "        average_weights.append([])\n",
    "        average_bias.append([])\n",
    "        for i in range(1, layer_count):\n",
    "            neurons_previous = layers_config[i-1]\n",
    "            neurons_current = layers_config[i]\n",
    "            single_layer_weights = np.random.normal(0, np.sqrt(2/neurons_previous), (neurons_current, neurons_previous))\n",
    "            single_layer_bias = np.random.normal(0, np.sqrt(2/neurons_previous), (neurons_current, 1))\n",
    "            weights.append(single_layer_weights)\n",
    "            bias.append(single_layer_bias)\n",
    "            average_weights.append(single_layer_weights)\n",
    "            average_bias.append(single_layer_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6180fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d877669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_path = \"mnist_traindata.hdf5\"\n",
    "with h5py.File(data_path, 'r') as hf:\n",
    "    train_x, train_y = hf['image'][...], hf['label'][...]\n",
    "    \n",
    "# split into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(xdata, ydata, test_size=500, random_state=1)\n",
    "\n",
    "epoch_size = 1\n",
    "batch_size = 500\n",
    "batch_numbers = int(len(X_train)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7f098cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1\n",
      "Running batch number 0 in epoch 1\n",
      "Running batch number 1 in epoch 1\n",
      "Running batch number 2 in epoch 1\n",
      "Running batch number 3 in epoch 1\n",
      "Running batch number 4 in epoch 1\n",
      "Running batch number 5 in epoch 1\n",
      "Running batch number 6 in epoch 1\n",
      "Running batch number 7 in epoch 1\n",
      "Running batch number 8 in epoch 1\n",
      "Running batch number 9 in epoch 1\n",
      "Running batch number 10 in epoch 1\n",
      "Running batch number 11 in epoch 1\n",
      "Running batch number 12 in epoch 1\n",
      "Running batch number 13 in epoch 1\n",
      "Running batch number 14 in epoch 1\n",
      "Running batch number 15 in epoch 1\n",
      "Running batch number 16 in epoch 1\n",
      "Running batch number 17 in epoch 1\n",
      "Running batch number 18 in epoch 1\n",
      "Running batch number 19 in epoch 1\n",
      "Running batch number 20 in epoch 1\n",
      "Running batch number 21 in epoch 1\n",
      "Running batch number 22 in epoch 1\n",
      "Running batch number 23 in epoch 1\n",
      "Running batch number 24 in epoch 1\n",
      "Running batch number 25 in epoch 1\n",
      "Running batch number 26 in epoch 1\n",
      "Running batch number 27 in epoch 1\n",
      "Running batch number 28 in epoch 1\n",
      "Running batch number 29 in epoch 1\n",
      "Running batch number 30 in epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasnain/wd/ec504project/working/ml/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in add\n",
      "  \n",
      "/home/hasnain/wd/ec504project/working/ml/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in add\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch number 31 in epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasnain/wd/ec504project/working/ml/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in matmul\n",
      "  if __name__ == '__main__':\n",
      "/home/hasnain/wd/ec504project/working/ml/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in matmul\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch number 32 in epoch 1\n",
      "Running batch number 33 in epoch 1\n",
      "Running batch number 34 in epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-26339902b12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0msample_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0ma_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mvalue_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-db2a34b3cc79>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(a, ground_output_y)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_count\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mh_derivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReLU_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdelta_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_derivative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdelta_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0maverage_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maverage_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Single Sample Updates\n",
    "shuffle_order = np.random.permutation(len(X_train))\n",
    "for i in range(1, epoch_size + 1):\n",
    "    print(\"Running Epoch {}\".format(i))\n",
    "    if i == 2:\n",
    "        eta = eta/2\n",
    "    if i == 3:\n",
    "        eta = eta/2\n",
    "    shuffle_order = np.random.permutation(len(X_train))\n",
    "    for j in range(batch_numbers):\n",
    "        print(\"Running batch number {} in epoch {}\".format(j, i))\n",
    "        for k in range(batch_size):\n",
    "            shuffle_index = j * batch_size + k\n",
    "            sample_x = X_train[shuffle_index]\n",
    "            sample_y = y_train[shuffle_index]\n",
    "            a_values = feedforward(sample_x)\n",
    "            backprop(a_values, sample_y)\n",
    "        for a in range(len(weights)):\n",
    "            value_weight = weights[a]\n",
    "            value_average_weight = np.multiply(average_weights[a], (eta/batch_size))\n",
    "            weights[a] = np.subtract(value_weight, value_average_weight)\n",
    "            value_bias = bias[a]\n",
    "            value_average_bias = np.multiply(average_bias[a], (eta/batch_size))\n",
    "            bias[a] = np.subtract(value_bias, value_average_bias)\n",
    "    print(\"Running feedforward on validation data for epoch {}\".format(i))\n",
    "    y_output = np.array([feedforward(X_val[m, :])[len(layers_config) - 1] for m in range(len(X_val))])\n",
    "    class_output = np.argmax(y_output, axis=0)\n",
    "    label_class = np.argmax(y_val, axis=0)\n",
    "    number_correct_classification = np.sum(class_output == label_class)\n",
    "    accuracy_val = number_correct_classification / len(X_val)\n",
    "    epoch_accuracy.append(accuracy_val)\n",
    "    print(\"Accuracy on Validation Set for epoch {} is {}\".format(epoch_size, accuracy_val))\n",
    "\n",
    "plt.plot(range(1, epoch_size + 1), epoch_accuracy)\n",
    "plt.title('Model accuracy after each epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axvline(x=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b405dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set for epoch 1 is 0.0\n"
     ]
    }
   ],
   "source": [
    "class_output = np.argmax(y_output, axis=0)\n",
    "label_class = np.argmax(y_val, axis=0)\n",
    "number_correct_classification = np.sum(class_output == label_class)\n",
    "accuracy_val = number_correct_classification / len(X_val)\n",
    "epoch_accuracy.append(accuracy_val)\n",
    "print(\"Accuracy on Validation Set for epoch {} is {}\".format(epoch_size, accuracy_val))\n",
    "\n",
    "#plt.plot(range(1, epoch_size + 1), epoch_accuracy)\n",
    "#plt.title('Model accuracy after each epoch')\n",
    "#plt.ylabel('Accuracy')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.axvline(x=1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f58e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Set Accuracy\n",
    "y_output = np.array([feedforward(X_train[i, :])[len(layers_config) - 1] for i in range(len(X_train))])\n",
    "class_output = np.argmax(y_output, axis=1)\n",
    "label_class = np.argmax(y_train, axis = 1)\n",
    "number_correct_classification = np.sum(class_output == label_class)\n",
    "accuracy_train = number_correct_classification/len(X_train)\n",
    "print(\"Accuracy on Training Set is {}\".format(accuracy_train))\n",
    "\n",
    "\n",
    "# Validation Set Accuracy\n",
    "y_output = np.array([feedforward(X_val[i, :])[len(layers_config) - 1] for i in range(len(X_val))])\n",
    "class_output = np.argmax(y_output, axis=1)\n",
    "label_class = np.argmax(y_val, axis = 1)\n",
    "number_correct_classification = np.sum(class_output == label_class)\n",
    "accuracy_val = number_correct_classification/len(X_val)\n",
    "print(\"Accuracy on Test Set is {}\".format(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8716ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87c271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
